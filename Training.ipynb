{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11073658,"sourceType":"datasetVersion","datasetId":6901116},{"sourceId":290891,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":249236,"modelId":270752}],"dockerImageVersionId":30920,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu117\n!pip install opencv-python-headless matplotlib tqdm pandas\n\n\n!git clone https://github.com/WongKinYiu/yolov7.git\n%cd yolov7\n\n\n!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\n\nimport os\nimport cv2\nimport torch\nimport numpy as np\nfrom tqdm import tqdm\nfrom torchvision import transforms\nfrom models.experimental import attempt_load\nfrom utils.general import non_max_suppression, scale_coords\nfrom utils.datasets import letterbox\nfrom utils.torch_utils import select_device\n\nclass Config:\n    def __init__(self):\n        self.device = select_device('0')\n        self.weights = 'yolov7.pt'\n        self.img_size = 512\n        self.batch_size = 16\n        self.conf_thres = 0.25  # Confidence threshold\n        self.iou_thres = 0.45  # IOU threshold for NMS\n        self.max_det = 1000  # Maximum number of detections per image\n        self.feature_dir = '/kaggle/working/features'\n        self.data_root = '/kaggle/input/dyslexia-handwriting/Processed'\n        \n        # Create feature directories\n        os.makedirs(os.path.join(self.feature_dir, 'Train', 'normal'), exist_ok=True)\n        os.makedirs(os.path.join(self.feature_dir, 'Train', 'reversal'), exist_ok=True)\n        os.makedirs(os.path.join(self.feature_dir, 'Train', 'corrected'), exist_ok=True)\n        os.makedirs(os.path.join(self.feature_dir, 'Test', 'normal'), exist_ok=True)\n        os.makedirs(os.path.join(self.feature_dir, 'Test', 'reversal'), exist_ok=True)\n        os.makedirs(os.path.join(self.feature_dir, 'Test', 'corrected'), exist_ok=True)\n\nconfig = Config()\n\nmodel = attempt_load(config.weights, map_location=config.device)  # load FP32 model\nmodel.eval()\nfeatures = {}\ndef get_features(name):\n    def hook(model, input, output):\n        features[name] = output.detach()\n    return hook\nmodel.model[-2].register_forward_hook(get_features('features'))\n\ndef preprocess_image(img_path):\n    img = cv2.imread(img_path)\n    if img is None:\n        return None\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32) / 255.0\n    \n    img = torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0)\n    \n    return img.to(config.device)\n\ndef extract_features(img_path):\n    img = preprocess_image(img_path)\n    if img is None:\n        return None\n    with torch.no_grad():\n        pred = model(img)\n    feature_map = features['features']\n    \n    pooled_features = torch.nn.functional.adaptive_avg_pool2d(feature_map, (1, 1))\n    pooled_features = pooled_features.squeeze(-1).squeeze(-1)\n    \n    return pooled_features.cpu().numpy()\n\ndef process_dataset(data_type='Train', class_name='normal'):\n    print(f\"Processing {data_type}/{class_name}...\")\n    \n    img_dir = os.path.join(config.data_root, data_type, class_name)\n    img_paths = [os.path.join(img_dir, f) for f in os.listdir(img_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n    \n    save_dir = os.path.join(config.feature_dir, data_type, class_name)\n    \n    for i in tqdm(range(0, len(img_paths), config.batch_size)):\n        batch_paths = img_paths[i:i+config.batch_size]\n        batch_features = []\n        \n        for img_path in batch_paths:\n            features = extract_features(img_path)\n            if features is not None:\n                batch_features.append(features)\n        \n        if batch_features:\n            batch_features = np.vstack(batch_features)\n            \n            for j, img_path in enumerate(batch_paths):\n                if j < len(batch_features):\n                    feature = batch_features[j]\n                    filename = os.path.splitext(os.path.basename(img_path))[0]\n                    np.save(os.path.join(save_dir, f\"{filename}.npy\"), feature)\n\nfor data_type in ['Train', 'Test']:\n    for class_name in ['normal', 'reversal', 'corrected']:\n        process_dataset(data_type, class_name)\n\nprint(\"Feature extraction completed!\")","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-05-04T07:09:10.609919Z","iopub.execute_input":"2025-05-04T07:09:10.610117Z","iopub.status.idle":"2025-05-04T09:03:00.933387Z","shell.execute_reply.started":"2025-05-04T07:09:10.610097Z","shell.execute_reply":"2025-05-04T09:03:00.932421Z"}},"outputs":[{"name":"stdout","text":"Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu117\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.5)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.26.4)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python-headless) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python-headless) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python-headless) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python-headless) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python-headless) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python-headless) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python-headless) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python-headless) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.2->opencv-python-headless) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.21.2->opencv-python-headless) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.21.2->opencv-python-headless) (2024.2.0)\nCloning into 'yolov7'...\nremote: Enumerating objects: 1197, done.\u001b[K\nremote: Total 1197 (delta 0), reused 0 (delta 0), pack-reused 1197 (from 1)\u001b[K\nReceiving objects: 100% (1197/1197), 74.23 MiB | 36.85 MiB/s, done.\nResolving deltas: 100% (520/520), done.\n/kaggle/working/yolov7\n--2025-05-04 07:09:22--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\nResolving github.com (github.com)... 140.82.112.4\nConnecting to github.com (github.com)|140.82.112.4|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250504%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250504T070922Z&X-Amz-Expires=300&X-Amz-Signature=e0a56ce9a8157bdf6b994a49943aeeb7458f7b0869cab8eac46875138d14879e&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream [following]\n--2025-05-04 07:09:22--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250504%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250504T070922Z&X-Amz-Expires=300&X-Amz-Signature=e0a56ce9a8157bdf6b994a49943aeeb7458f7b0869cab8eac46875138d14879e&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream\nResolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\nConnecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 75587165 (72M) [application/octet-stream]\nSaving to: ‘yolov7.pt’\n\nyolov7.pt           100%[===================>]  72.08M   180MB/s    in 0.4s    \n\n2025-05-04 07:09:23 (180 MB/s) - ‘yolov7.pt’ saved [75587165/75587165]\n\n","output_type":"stream"},{"name":"stderr","text":"/kaggle/working/yolov7/models/experimental.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ckpt = torch.load(w, map_location=map_location)  # load\n","output_type":"stream"},{"name":"stdout","text":"Fusing layers... \nRepConv.fuse_repvgg_block\nRepConv.fuse_repvgg_block\nRepConv.fuse_repvgg_block\nProcessing Train/normal...\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/2459 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n100%|██████████| 2459/2459 [20:44<00:00,  1.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing Train/reversal...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2924/2924 [25:03<00:00,  1.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing Train/corrected...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4096/4096 [36:35<00:00,  1.87it/s]  \n","output_type":"stream"},{"name":"stdout","text":"Processing Test/normal...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1223/1223 [10:53<00:00,  1.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing Test/reversal...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1118/1118 [09:34<00:00,  1.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing Test/corrected...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1206/1206 [10:29<00:00,  1.92it/s]","output_type":"stream"},{"name":"stdout","text":"Feature extraction completed!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# First ensure all required imports are present\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\nfrom sklearn.utils.class_weight import compute_class_weight\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Configuration class remains the same\nclass Config:\n    def __init__(self):\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.feature_dir = '/kaggle/working/features'\n        self.num_classes = 3  # normal, reversal, corrected\n        self.batch_size = 32\n        self.learning_rate = 0.001  # Reduced from original\n        self.epochs = 200\n        self.class_names = ['normal', 'reversal', 'corrected']\n        self.class_to_idx = {name: i for i, name in enumerate(self.class_names)}\n        \nconfig = Config()\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# Dataset class remains the same\nclass DyslexiaDataset(Dataset):\n    def __init__(self, data_type='Train'):\n        self.data = []\n        self.labels = []\n        \n        for class_name in config.class_names:\n            class_dir = os.path.join(config.feature_dir, data_type, class_name)\n            for feature_file in os.listdir(class_dir):\n                if feature_file.endswith('.npy'):\n                    feature_path = os.path.join(class_dir, feature_file)\n                    self.data.append(feature_path)\n                    self.labels.append(config.class_to_idx[class_name])\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        feature = np.load(self.data[idx])\n        return torch.from_numpy(feature).float(), self.labels[idx]\n\n# Enhanced Model Architecture\nclass EnhancedMobileNetV2(nn.Module):\n    def __init__(self, num_classes=3):\n        super().__init__()\n        self.features = nn.Sequential(\n            nn.Conv1d(1, 32, kernel_size=3, padding=1),\n            nn.BatchNorm1d(32),\n            nn.ReLU6(),\n            nn.MaxPool1d(2),\n            \n            nn.Conv1d(32, 64, kernel_size=3, padding=1),\n            nn.BatchNorm1d(64),\n            nn.ReLU6(),\n            nn.MaxPool1d(2),\n            \n            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm1d(128),\n            nn.ReLU6(),\n            nn.MaxPool1d(2),\n            \n            nn.Conv1d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm1d(256),\n            nn.ReLU6(),\n            nn.AdaptiveAvgPool1d(1)\n        )\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.6),\n            nn.Linear(256, 128),\n            nn.ReLU6(),\n            nn.Linear(128, num_classes)\n        )\n    \n    def forward(self, x):\n        x = x.unsqueeze(1)  # Add channel dimension\n        x = self.features(x)\n        x = x.view(x.size(0), -1)  # Flatten\n        return self.classifier(x)\n\n# Calculate class weights\ndef get_class_weights(dataset):\n    labels = dataset.labels\n    class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n    return torch.tensor(class_weights, dtype=torch.float).to(config.device)\n\n# Enhanced training function\ndef train_model_enhanced():\n    # Initialize model\n    model = EnhancedMobileNetV2(config.num_classes).to(config.device)\n    \n    # Handle class imbalance\n    class_weights = get_class_weights(train_dataset)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    \n    # Optimizer with weight decay\n    optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate, weight_decay=1e-4)\n    \n    # Learning rate scheduler\n    scheduler = ReduceLROnPlateau(optimizer, 'max', patience=5, factor=0.5, verbose=True)\n    \n    best_accuracy = 0.0\n    \n    print(\"Starting enhanced training...\")\n    for epoch in range(config.epochs):\n        model.train()\n        running_loss = 0.0\n        correct = 0\n        total = 0\n        \n        for features, labels in train_loader:\n            features, labels = features.to(config.device), labels.to(config.device)\n            \n            # Simple data augmentation\n            if np.random.rand() > 0.5:\n                features += torch.randn_like(features) * 0.01  # Add small noise\n            \n            optimizer.zero_grad()\n            outputs = model(features)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            \n            # Gradient clipping\n            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            \n            optimizer.step()\n            \n            # Track metrics\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n        \n        epoch_acc = 100 * correct / total\n        print(f'Epoch [{epoch+1}/{config.epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {epoch_acc:.2f}%')\n        \n        # Validation\n        val_acc = validate_model(model)\n        scheduler.step(val_acc)\n        \n        # Save best model\n        if val_acc > best_accuracy:\n            best_accuracy = val_acc\n            torch.save(model.state_dict(), 'best_model.pth')\n            print(f'New best model saved with val accuracy: {best_accuracy:.2f}%')\n    \n    # Load best model before return\n    model.load_state_dict(torch.load('best_model.pth'))\n    return model\n\ndef validate_model(model):\n    model.eval()\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for features, labels in test_loader:\n            features, labels = features.to(config.device), labels.to(config.device)\n            outputs = model(features)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    return 100 * correct / total\n\n# Enhanced evaluation\ndef evaluate_model_enhanced(model):\n    model.eval()\n    all_preds = []\n    all_labels = []\n    all_probs = []\n    \n    with torch.no_grad():\n        correct = 0\n        total = 0\n        for features, labels in test_loader:\n            features, labels = features.to(config.device), labels.to(config.device)\n            outputs = model(features)\n            _, predicted = torch.max(outputs.data, 1)\n            probs = torch.softmax(outputs, dim=1)\n            \n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n            all_probs.extend(probs.cpu().numpy())\n        \n        accuracy = 100 * correct / total\n        mAP, mIoU, f1 = calculate_enhanced_metrics(np.array(all_preds), \n                                                np.array(all_labels),\n                                                np.array(all_probs),\n                                                config.num_classes)\n        \n        print(f'\\nEnhanced Test Metrics:')\n        print(f'Accuracy: {accuracy:.2f}%')\n        print(f'Weighted mAP: {mAP:.4f}')\n        print(f'Weighted mIoU: {mIoU:.4f}')\n        print(f'Weighted F1 Score: {f1:.4f}')\n        \n        print('\\nClassification Report:')\n        print(classification_report(all_labels, all_preds, \n                                target_names=config.class_names,\n                                digits=4))\n        \n        # Confusion matrix\n        cm = confusion_matrix(all_labels, all_preds)\n        plt.figure(figsize=(10,8))\n        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                  xticklabels=config.class_names,\n                  yticklabels=config.class_names)\n        plt.title('Confusion Matrix')\n        plt.xlabel('Predicted')\n        plt.ylabel('Actual')\n        plt.show()\n\ndef calculate_enhanced_metrics(all_preds, all_labels, all_probs, num_classes):\n    # Weighted mAP\n    aps = []\n    for cls in range(num_classes):\n        tp = np.sum((all_preds == cls) & (all_labels == cls))\n        fp = np.sum((all_preds == cls) & (all_labels != cls))\n        precision = tp / (tp + fp + 1e-10)\n        aps.append(precision)\n    \n    # Weight by class support\n    class_counts = np.bincount(all_labels)\n    weights = class_counts / len(all_labels)\n    weighted_mAP = np.sum(np.array(aps) * weights)\n    \n    # Weighted mIoU\n    ious = []\n    for cls in range(num_classes):\n        intersection = np.sum((all_preds == cls) & (all_labels == cls))\n        union = np.sum((all_preds == cls) | (all_labels == cls))\n        ious.append(intersection / (union + 1e-10))\n    weighted_mIoU = np.sum(np.array(ious) * weights)\n    \n    # Weighted F1\n    precision, recall, f1, _ = precision_recall_fscore_support(\n        all_labels, all_preds, average='weighted')\n    \n    return weighted_mAP, weighted_mIoU, f1\n\n# Initialize datasets\ntrain_dataset = DyslexiaDataset('Train')\ntest_dataset = DyslexiaDataset('Test')\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False)\n\n# Run the enhanced pipeline\nprint(\"Starting training pipeline...\")\nenhanced_model = train_model_enhanced()\nprint(\"\\nEvaluating model...\")\nevaluate_model_enhanced(enhanced_model)","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-05-04T10:08:06.991998Z","iopub.execute_input":"2025-05-04T10:08:06.992315Z","iopub.status.idle":"2025-05-04T10:08:07.043065Z","shell.execute_reply.started":"2025-05-04T10:08:06.992288Z","shell.execute_reply":"2025-05-04T10:08:07.041786Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-061a92097adb>\u001b[0m in \u001b[0;36m<cell line: 254>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;31m# Initialize datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDyslexiaDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDyslexiaDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-061a92097adb>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_type)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mclass_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfeature_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                     \u001b[0mfeature_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/features/Train/normal'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/working/features/Train/normal'","output_type":"error"}],"execution_count":2}]}